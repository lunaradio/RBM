{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Ising spins and Calculating Hamiltonian of the Ising system\n",
    "class Ising():\n",
    "    \n",
    "    def __init__(self, nRow, nCol):\n",
    "        self.spins = torch.zeros(nRow, nCol)\n",
    "        self.probs = torch.rand(nRow, nCol)\n",
    "        for i in range(nRow):\n",
    "            for j in range(nCol):\n",
    "                if self.probs[i][j] < 0.5:\n",
    "                    self.spins[i][j] = 1\n",
    "                else:\n",
    "                    self.spins[i][j] = -1\n",
    "    \n",
    "    def Hamiltonian(self):\n",
    "        H = 0.\n",
    "        J = 1.\n",
    "        nRow = self.spins.size()[0]\n",
    "        nCol = self.spins.size()[1]\n",
    "        for i in range(nRow):\n",
    "            for j in range(nCol):\n",
    "                if i < 1:\n",
    "                    H -= J * self.spins[i][j] * self.spins[i+1][j]\n",
    "                elif i > nRow - 2:\n",
    "                    H -= J * self.spins[i][j] * self.spins[i-1][j]\n",
    "                else:\n",
    "                    H -= J * self.spins[i][j] * self.spins[i+1][j]\n",
    "                    H -= J * self.spins[i][j] * self.spins[i-1][j]\n",
    "                \n",
    "                if j < 1:\n",
    "                    H -= J * self.spins[i][j] * self.spins[i][j+1]\n",
    "                elif j > nCol - 2:\n",
    "                    H -= J * self.spins[i][j] * self.spins[i][j-1]\n",
    "                else:\n",
    "                    H -= J * self.spins[i][j] * self.spins[i][j+1]\n",
    "                    H -= J * self.spins[i][j] * self.spins[i][j-1]\n",
    "        return H/2   #to avoid double count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the RBM Architecture (weights, biases)\n",
    "class RBM():\n",
    "    \n",
    "    # Initiate RBM parameters\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(nh)\n",
    "        self.b = torch.randn(nv)\n",
    "    \n",
    "    def Hamiltonian(self, v, h): \n",
    "        ah = torch.dot(self.a, h)\n",
    "        bv = torch.dot(self.b, v)\n",
    "        hWv = torch.dot(h, torch.mv(self.W, v))\n",
    "        H = - ah - bv - hWv\n",
    "        return H\n",
    "    \n",
    "    def FreeEnergy(self, v):\n",
    "        bv = torch.dot(self.b, v)\n",
    "        Wv = torch.mv(self.W, v)\n",
    "        F = - bv\n",
    "        for i in range(Wv.size()[0]):\n",
    "            F -= torch.log(1 + torch.exp(self.a[i] + Wv[i]))\n",
    "        return F\n",
    "    \n",
    "    # Calculate p(v = D[i]) using Softmax\n",
    "    def p_v(self, D):\n",
    "        # Free Energies of each v = D[i]\n",
    "        F = torch.tensor(D.size()[0])\n",
    "        for i in range(D.size()[0]):\n",
    "            F[i] = self.FreeEnergy(D[i])\n",
    "            \n",
    "        # p(v = D[i]) = Softmax(-F)[i] = exp(-F[i])/Z\n",
    "        p_v = F.softmax(- F, dim = 0)\n",
    "        return p_v\n",
    "    \n",
    "    # Calculate Negative Log-Likelihood using log_softmax\n",
    "    def NLL(self, D):\n",
    "        # Free Energies of each v = D[i]\n",
    "        F = torch.zeros(D.size()[0])\n",
    "        for i in range(D.size()[0]):\n",
    "            F[i] = self.FreeEnergy(D[i])\n",
    "            \n",
    "        # p(v = D[i]) = Softmax(-F)[i] = exp(-F[i])/Z\n",
    "        LSM = F.log_softmax(- F, dim = 0)\n",
    "        NLL = - torch.mean(LSM)\n",
    "        return NLL\n",
    "    \n",
    "    def sigmoid_i(self, D, idx):\n",
    "        a = self.a\n",
    "        WD_i = torch.mv(self.W, D[idx])\n",
    "        sigmoid = torch.sigmoid(a + WD_i)\n",
    "        return sigmoid\n",
    "    \n",
    "    def grad_F_i(self, D, idx, param):\n",
    "        \n",
    "        grad_F_i = torch.zeros_like(param)\n",
    "        \n",
    "        if param == self.W:\n",
    "            for j in range(grad_F_i.size()[0]):\n",
    "                for k in range(grad_F_i.zie()[1]):\n",
    "                    grad_F_i[j,k] = - self.sigmoid_i(D, idx)[j] * D[idx][k]\n",
    "        \n",
    "        elif param == self.a:\n",
    "            for j in range(grad_F_i.size()[0]):\n",
    "                grad_F_i[j] = - self.sigmoid_i(D, idx)[j]\n",
    "        \n",
    "        elif param == self.b:\n",
    "            for j in range(grad_F_i.size()[0]):\n",
    "                grad_F_i[j] = - D[idx][j]\n",
    "        \n",
    "        return grad_F_i\n",
    "        \n",
    "    # Gradients of Negative Log-Likelihood\n",
    "    def grad_NLL(self, D, param):\n",
    "        \n",
    "        grad_NLL = torch.zeros_like(param)\n",
    "        nData = D.size()[0]\n",
    "        \n",
    "        for idx in range(nData):\n",
    "            grad_NLL += (1 / nData - self.p_v(D)[idx]) * self.grad_F_i(D, idx, param)\n",
    "        \n",
    "        return grad_NLL\n",
    "    \n",
    "    # Update the RBM parameters\n",
    "    def update(self, D, learning_rate):\n",
    "\n",
    "        grad_NLL_w = self.grad_NLL(D, self.W)\n",
    "        grad_NLL_a = self.grad_NLL(D, self.a)\n",
    "        grad_NLL_b = self.grad_NLL(D, self.b)\n",
    "        \n",
    "        self.W -= learning_rate * grad_NLL_w\n",
    "        self.a -= learning_rate * grad_NLL_a\n",
    "        self.b -= learning_rate * grad_NLL_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to create a training data set by using Metropolis algorithm\n",
    "def Data_for_train(nData, nRow, nCol):\n",
    "\n",
    "    for i in range(nData):\n",
    "    \n",
    "        ising = Ising(nRow, nCol)\n",
    "        H_new = ising.Hamiltonian()\n",
    "    \n",
    "        # Reshape of a matrix of Ising spins to a vector as the visible layer\n",
    "        spin = ising.spins.view(nRow*nCol)\n",
    "        v = (1 - spin)/2   # spin 1 --> 0 ,   spin -1 --> 1\n",
    "    \n",
    "        # save visible layers as row vectors of the training data matrix\n",
    "        if i == 0:\n",
    "            data = v.unsqueeze(0)\n",
    "        else:\n",
    "            if H_new <= H:\n",
    "                data = torch.cat((data, v.unsqueeze(0)), dim = 0)\n",
    "            else:\n",
    "                B_dist = dist.Bernoulli(torch.exp(H - H_new))\n",
    "                B = B_dist.sample()\n",
    "                if B == 1:\n",
    "                    data = torch.cat((data, v.unsqueeze(0)), dim = 0)\n",
    "                else:\n",
    "                    data = torch.cat((data, data[i-1].unsqueeze(0)), dim = 0)\n",
    "        H = H_new\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initiate the data set and RBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 0., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 1., 0., 1., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 1., 0., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# make a training data set\n",
    "D = Data_for_train(nData = 10, nRow = 3, nCol = 3)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RBM parameters\n",
    "rbm = RBM(nv = D.size()[1], nh = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: W = tensor([[-0.0865, -1.1715,  1.9859, -0.8708, -1.9439, -0.7002,  0.2207, -0.0337,\n",
      "          0.6944],\n",
      "        [ 0.4498, -1.2088,  0.0212, -0.6390, -1.1836, -0.2431, -0.2546,  0.3451,\n",
      "         -0.8594],\n",
      "        [-0.9171, -0.9272, -0.9411,  0.6640, -0.5215,  0.0513,  0.9389, -0.8708,\n",
      "          0.2203],\n",
      "        [-0.0895,  0.0512,  0.2192,  0.3970,  1.8720, -0.0586, -1.1166, -0.1206,\n",
      "          0.2534]])\n",
      "\t a = tensor([ 0.1404, -0.6201,  0.3777,  0.1046])\n",
      "\t b = tensor([ 0.7695, -1.2405, -0.9675, -0.9408, -1.8358, -1.2833,  0.9706, -1.8494,\n",
      "        -0.3973])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c61d325765f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch {}: W = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5d847b9ced47>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, D, learning_rate)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mgrad_NLL_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_NLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mgrad_NLL_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_NLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mgrad_NLL_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_NLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5d847b9ced47>\u001b[0m in \u001b[0;36mgrad_NLL\u001b[0;34m(self, D, param)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mgrad_NLL\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnData\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_F_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_NLL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5d847b9ced47>\u001b[0m in \u001b[0;36mp_v\u001b[0;34m(self, D)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFreeEnergy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# p(v = D[i]) = Softmax(-F)[i] = exp(-F[i])/Z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "# Train the RBM\n",
    "num_epoch = 100\n",
    "#batch_size = 1\\\n",
    "lr = 1e-3  #learning_rate\n",
    "\n",
    "for epoch in range(0, num_epoch + 1):\n",
    "        \n",
    "    if epoch > 0:\n",
    "        rbm.update(D, lr)\n",
    "    \n",
    "    print('epoch {}: W = {}'.format(epoch, rbm.W))\n",
    "    print('\\t a = {}'.format(rbm.a))\n",
    "    print('\\t b = {}'.format(rbm.b))\n",
    "    #print('\\t loss = {}'.format(rbm.NLL(D)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
